#' Input for \code{\link{tempted}}.
#' @param resolution Number of time points to evaluate the value of the temporal loading function.
#' Default is set to 101. It does not affect the subject or feature loadings. Input for \code{\link{tempted}}.
#' @param maxiter Maximum number of iteration. Default is 20. Input for \code{\link{tempted}}.
#' @param epsilon Convergence criteria for difference between iterations. Default is 1e-4. Input for \code{\link{tempted}}.
#' @param r.svd The number of ranks in the mean structure. Default is 1. Input for \code{svd_centraliz}
#' @param pct.ratio The percent of features to sum up. Default is 0.05, i.e. 5%.
#' Input for \code{\link{ratio_feature}}.
#' @param absolute \code{absolute = TRUE} means features are ranked by the absolute value of feature loadings,
#' and the top \code{pct.ratio} percent of features are picked.
#' \code{absolute = FALSE} means features are ranked by the original value of feature loadings,
#' and the top and bottom \code{pct.ratio} percent of features are picked.
#' Then ratio is taken as the abundance of the features with positive loading
#' over the abundance of the features with negative loading.
#' Input for \code{\link{ratio_feature}}.
#' @param pct.aggregate The percent of features to aggregate,
#' features ranked by absolute value of the feature loading of each component.
#' Default is 1, which means 100% of features are aggregated.
#' Setting \code{pct.aggregate=0.01} means top 1% of features is aggregated,
#' where features are ranked in absolute value of feature loading of each component.
#' Input for \code{\link{aggregate_feature}}.
#' @param contrast A matrix choosing how components are combined,
#' each column is a contrast of length r and used to calculate the linear combination of
#' the feature loadings of r components.
#' Input for \code{\link{ratio_feature}} and Input for \code{\link{aggregate_feature}}.
#' @return A list including all the input and output of functions \code{\link{format_tempted}}, \code{svd_centralize()}, \code{\link{tempted}},
#' \code{\link{ratio_feature}}, and \code{\link{aggregate_feature}}.
#' \item{input}{All the input options of function \code{tempted_all()}.}
#' \item{datlist_raw}{}
#' \item{datlist}{}
#' \item{mean_svd}{}
#' \item{A.hat}{Subject loading, a subject by r matrix.}
#' \item{B.hat}{Feature loading, a feature by r matrix.}
#' \item{Phi.hat}{Temporal loading function, a resolution by r matrix.}
#' \item{time.Phi}{The time points where the temporal loading function is evaluted.}
#' \item{Lambda}{Eigen value, a length r vector.}
#' \item{r.square}{Variance explained by each component.
#' This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using individual components.}
#' \item{accum.r.square}{Variance explained by the first few components accumulated.
#' This is the R-squared of the linear regression of the vectorized temporal tensor against the vectorized low-rank reconstruction using the first few components.}
#' \item{metafeature.ratio}{The log ratio abundance of the top over bottom ranking features.
#' It is a data.frame with five columns: "value" for the log ratio values,
#' "subID" for the subject ID, and "timepoint" for the time points,
#' and "PC" indicating which component was used to construct the meta feature.}
#' \item{toppct.ratio}{A matrix of TRUE/FALSE indicating which features are ranked top in each component (and contrast)
#' and used as the numerator of the log ratio.}
#' \item{bottompct.ratio}{A matrix of TRUE/FALSE indicating which features are ranked bottom in each component (and contrast)
#' and used as the denominator of the log ratio.}
#' #' \item{metafeature.aggregate}{The meta feature obtained by aggregating the observed temporal tensor.
#' It is a data.frame with four columns: "value" for the meta feature values,
#' "subID" for the subject ID, "timepoint" for the time points,
#' and "PC" indicating which component was used to construct the meta feature.}
#' \item{toppct.aggregate}{A matrix of TRUE/FALSE indicating which features are aggregated in each component and contrast.}
#' \item{contrast}{The contrast used to linearly combine the components.
#' It is from the input parameter \code{contrast}.}
#' @examples
#' res_processed <- tempted_all(processed_table, meta_table$day_of_life, meta_table$studyid,
#' threshold=1, transform="none",
#' r=2, smooth=1e-5)
#' res_count <- tempted_all(count_table, meta_table$day_of_life, meta_table$studyid,
#' threshold=0.95, transform="clr", pseudo_count=0.5,
#' r=2, smooth=1e-5)
#' res_proportion <- tempted_all(count_table/rowSums(count_table), meta_table$day_of_life, meta_table$studyid,
#' threshold=0.95, transform="clr", pseudo_count=NULL,
#' r=2, smooth=1e-5)
tempted_all <- function(feature_table, time_point, subjectID,
threshold=0.95, pseudo_count=NULL, transform="clr",
r = 3, smooth=1e-6,
interval = NULL, resolution = 51,
maxiter=20, epsilon=1e-4,
r.svd=1,
pct.ratio=0.05, absolute=FALSE,
pct.aggregate=1, contrast=NULL){
datlist <- format_tempted(feature_table=feature_table, time_point=time_point, subjectID=subjectID,
threshold=threshold, pseudo_count=pseudo_count, transform=transform)
datlist_raw <- format_tempted(feature_table=feature_table, time_point=time_point, subjectID=subjectID,
threshold=threshold, pseudo_count=pseudo_count, transform="none")
mean_svd <- svd_centralize(datlist, r.svd)
res_tempted <- tempted(datlist=mean_svd$datlist, r = r, smooth=smooth,
interval = interval, resolution = resolution,
maxiter=maxiter, epsilon=epsilon)
res_ratio <- ratio_feature(res_tempted=res_tempted, datlist=datlist_raw,
pct=pct.ratio, absolute=absolute, contrast=contrast)
res_aggfeat <- aggregate_feature(res_tempted=res_tempted, mean_svd=mean_svd, datlist=datlist,
pct=pct.aggregate, contrast=contrast)
res_all <- list(input=as.list(match.call()))
res_all$datlist_raw <- datlist_raw
res_all$datlist <- datlist
res_all <- append(res_all, res_tempted)
res_all$metafeature.ratio <- res_ratio$metafeature.ratio
res_all$toppct.ratio <- res_ratio$toppct
res_all$bottompct.ratio <- res_ratio$toppct
res_all$metafeature.aggregate <- res_aggfeat$metafeature.aggregate
res_all$toppct.aggregate <- res_aggfeat$toppct
res_all$contrast <- contrast
return(res_all)
}
#' @title Plot nonparametric smoothed mean and error bands of features versus time
#' @description This is a handy function to plot the smoothed mean and error bands for multiple features.
#' @param feature_mat A sample by feature matrix. Each feature will be plotted separately as a facet.
#' The features can be original features, meta features, log ratios, or any variables of interest.
#' @param time_vec A vector of time points matched to the rows of \code{feature_mat}.
#' @param group_vec A vector of factor variable indicating the group membership
#' of samples matched to the rows of \code{feature_mat}.
#' @param coverage The coverage rate for the error band. Default is 0.95.
#' @param bws The smoothness parameter for the smoothing lines and error bands.
#' A larger value means a smoother line.
#' Default is NULL and calculated by function \code{np::npreg()}.
#' @param nrow The number of rows to plot the features used in function \code{ggplot2::facet_wrap()}.
#' @return A ggplot2 object.
plot_feature_summary <- function(feature_mat, time_vec, group_vec,
coverage=0.95, bws=NULL, nrow=1){
nfeature <- ncol(feature_mat)
if(class(group_vec)!='factor') group_vec <- as.factor(group_vec)
group_level <- levels(group_vec)
time_all <- NULL
mean_all <- NULL
merr_all <- NULL
feature_all <- NULL
group_all <- NULL
if(is.null(colnames(feature_mat))){stop('feature_mat needs to have column names!')}
CI_length <- -qnorm((1-coverage)/2)
for (jj in 1:nfeature){
for (ii in 1:length(group_level)){
ind <- group_vec==group_level[ii]
if(is.null(bws)){
model.np <- npreg(feature_mat[ind,jj]~time_vec[ind],
regtyle="ll", bwmethod="cv.aic")
}else{
model.np <- npreg(feature_mat[ind,jj]~time_vec[ind], bws=bws,
regtyle="ll", bwmethod="cv.aic")
}
time_eval <- as.vector(t(model.np$eval))
mean_eval <- model.np$mean[order(time_eval)]
merr_eval <- model.np$merr[order(time_eval)]
time_eval <- sort(time_eval)
time_all <- c(time_all, time_eval)
mean_all <- c(mean_all, mean_eval)
merr_all <- c(merr_all, merr_eval)
feature_all <- c(feature_all,
rep(colnames(feature_mat)[jj], length(time_eval)))
group_all <- c(group_all,
rep(group_level[ii], length(time_eval)))
}
}
group_all <- factor(group_all, levels=group_level)
tab_summary <- data.frame(time=time_all, mean=mean_all, merr=merr_all,
group=group_all, feature=feature_all)
p_summary <- ggplot(data=tab_summary,
aes(x=time, y=mean, group=group, color=group)) +
geom_line() +
geom_ribbon(aes(ymin=mean-CI_length*merr, ymax=mean+CI_length*merr,
color=group, fill=group), linetype=2, alpha=0.3) +
ylab(paste0('mean +/- ', round(CI_length,2), '*se')) + facet_wrap(.~feature, scales="free", nrow=nrow)
return(p_summary)
}
#' @title Plot nonparametric smoothed mean and error bands of meta features versus time
#' @description This function plot the smoothed mean and error band of meta features
#' grouped by a factor variable provided by the user.
#' @param metafeature It can be \code{metafeature.ratio} from the output of \code{\link{ratio_feature}} and \code{tempted_all()},
#' \code{metafeature.aggregate} from the output of \code{\link{ratio_feature}} and \code{tempted_all()},
#' or \code{metafeature.aggregate.est} from the output of \code{\link{ratio_feature}}.
#' @param group A subject by 2 data.frame with the first column for subject ID and second column for group membership.
#' @param coverage The coverage rate for the error band. Default is 0.95.
#' @param bws The smoothness parameter for the smoothing lines and error bands.
#' A larger value means a smoother line.
#' Default is NULL and calculated by function \code{np::npreg()}.
#' @param nrow The number of rows to plot the features used in function \code{ggplot2::facet_wrap()}.
#' @return A ggplot2 object.
plot_metafeature <- function(metafeature, group,
coverage=0.95, bws=NULL, nrow=1){
colnames(group) <- c("subID", "group")
tab_feat_ratio <- merge(metafeature, group, by="subID")
## summed up, by mean and sd
reshape_feat_ratio <- reshape(tab_feat_ratio,
idvar=c("subID","timepoint") ,
v.names=c("value"), timevar="PC",
direction="wide")
CC <- grep('value',colnames(reshape_feat_ratio))
colnames(reshape_feat_ratio)[CC] <- substr(colnames(reshape_feat_ratio)[CC], start=7, stop=100)
feature_mat_ratio <- reshape_feat_ratio[,CC]
colnames(feature_mat_ratio)
time_vec_ratio <- reshape_feat_ratio$timepoint
group_vec_ratio <- factor(reshape_feat_ratio$group)
p_feat_summary <- plot_feature_summary(feature_mat_ratio,
time_vec_ratio,
group_vec_ratio, bws=bws, nrow=nrow)
return(p_feat_summary)
}
#' @title Plot the temporal loading functions
#' @description This function uses \code{ggplot2::geom_line()} in ggplot2 to plot the temporal loading functions from \code{\link{tempted}}.
#' @param res Output of function \code{\link{tempted}}.
#' @param r The number of components to plot. By default all the components estimated by \code{\link{tempted}} will be plotted.
#' @param ... Arguments to put in \code{ggplot2::geom_line(aes(...))}.
#' @return An ggplot2 object.
plot_time_loading <- function(res, r=NULL, ...){
Phi.data <- res$Phi.hat
if(is.null(r)) r <- ncol(Phi.data)
Phi.data <- Phi.data[,1:r]
ntime <- nrow(Phi.data)
Phi.data <- data.frame(time=res$time.Phi, value=as.vector(Phi.data),
component=as.factor(as.vector(t(matrix(rep(1:r,ntime),r,)))))
ptime <- ggplot(data=Phi.data, aes(x=time, y=value, color=component)) + geom_line(aes(...))
return(ptime)
}
res_proportion <- tempted_all(count_table/rowSums(count_table), meta_table$day_of_life, meta_table$studyid,
threshold=0.95, transform="clr", pseudo_count=NULL,
r=3, smooth=1e-5)
plot_time_loading(res_proportion)
plot_time_loading(res_proportion, r=2)
plot_metafeature(res_proportion$metafeature.aggregate, meta_table$delivery)
plot_metafeature(res_proportion$metafeature.aggregate, meta_table[,c("studyID", "delivery")])
plot_metafeature(res_proportion$metafeature.aggregate, meta_table[,c("studyid", "delivery")])
plot_metafeature(res_proportion$metafeature.aggregate, meta_table[,c("studyid", "delivery")], bws=3)
plot_metafeature(res_proportion$metafeature.aggregate, meta_table[,c("studyid", "delivery")], bws=8)
plot_metafeature(res_proportion$metafeature.aggregate, meta_table[,c("studyid", "delivery")], bws=30)
plot_metafeature(res_proportion$metafeature.ratio, meta_table[,c("studyid", "delivery")], bws=30)
metafeature=res_proportion$metafeature.aggregate
group <- meta_table[,c("studyid", "delivery")]
coverage=0.95
bws=30
nrow=1
colnames(group) <- c("subID", "group")
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(tab_feat_ratio)
dim(metafeature)
colnames(metafeature)
colnames(grouop)
colnames(group)
summary(group$subID)
group$subID <- as.factor(group$subID)
summary(tab_feat_ratio$subID)
colnames(group) <- c("subID", "group")
tab_feat_ratio <- merge(metafeature, group, by="subID")
## summed up, by mean and sd
reshape_feat_ratio <- reshape(tab_feat_ratio,
idvar=c("subID","timepoint") ,
v.names=c("value"), timevar="PC",
direction="wide")
dim(tab_feat_ratio)
group$subID <- as.character(group$subID)
colnames(group) <- c("subID", "group")
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(tab_feat_ratio)
unique(group$subID)
unique(metafeature$subID)
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(metafeature)
dim(tab_feat_ratio)
head(tab_feat_ratio)
head(metafeature)
rownames(group)
rownames(group) <- NULL
rownames(meta_fea)
rownames(metafeature)
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(tab_feat_ratio)
rownames(metafeature) <- NULL
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(tab_feat_ratio)
rownames(group)
dim(group)
group <- unique(group)
dim(group)
colnames(group) <- c("subID", "group")
tab_feat_ratio <- merge(metafeature, group, by="subID")
dim(tab_feat_ratio)
plot_metafeature(res_proportion$metafeature.ratio, unique(meta_table[,c("studyid", "delivery"))], bws=30)
plot_metafeature(res_proportion$metafeature.ratio, unique(meta_table[,c("studyid", "delivery")]), bws=30)
plot_metafeature(res_proportion$metafeature.aggregate, unique(meta_table[,c("studyid", "delivery")]), bws=30)
format_tempted
head(format_tempted())
head(format_tempted
)
class(meta_table$studyid)
meta_table$studyid <- as.character(meta_table$studyid)
save(meta_table, file="data/meta_table.rda")
class(meta_table$studyid)
head(format_tempted())
head(format_tempted)
datlist <- format_tempted(count_table, meta_table$day_of_life, meta_table$studyid,
pseudo_count=0.5, transform="clr")
mean_svd <- svd_centralize(datlist, r=1)
res_tempted <- tempted(mean_svd$datlist, r=3, smooth=1e-5)
plot_time_loading(res_tempted)
plot_time_loading(res_tempted, r=2)
datlist <- format_tempted(processed_table, meta_table$day_of_life, meta_table$studyid,
pseudo_count=NULL, transform="none")
mean_svd <- svd_centralize(datlist, r=1)
res_tempted <- tempted(mean_svd$datlist, r=3, smooth=1e-5)
plot_time_loading(res_tempted)
plot_time_loading(res_tempted, r=2)
plot_metafeature(res_tempted, unique(meta_table[,c("studyid", "delivery")]), bws=30)
group <- unique(meta_table[,c("studyid", "delivery")])
plot_metafeature(res_tempted, group, bws=30)
plot_time_loading(res_tempted, r=2)
plot_metafeature(res_tempted$metafeature.aggregate, group, bws=30)
dim(res_tempted$metafeature.aggregate)
names(res_tempted)
plot_time_loading(res_proportion)
plot_metafeature(res_proportion, group, bws=30)
plot_metafeature(res_proportion$metafeature.aggregate, group, bws=30)
plot_feature_summary(count_table/rowSums(count_table)[,1:3],
meta_table$day_of_life, meta_table$delivery, bws=30)
plot_feature_summary((count_table/rowSums(count_table))[,1:3],
meta_table$day_of_life, meta_table$delivery, bws=30)
plot_feature_summary((count_table/rowSums(count_table))[,c("OTU4447072", "OTU4447447")],
meta_table$day_of_life, meta_table$delivery, bws=30)
colnames(count_table)
plot_feature_summary((count_table/rowSums(count_table))[,c("OTU4447072", "OTU4467447")],
meta_table$day_of_life, meta_table$delivery, bws=30)
datlist <- format_tempted(count_table, meta_table$day_of_life, meta_table$studyid,
pseudo_count=0.5, transform="clr")
mean_svd <- svd_centralize(datlist, r=1)
res_tempted <- tempted(mean_svd$datlist, r=3, smooth=1e-5)
datlist_raw <- format_tempted(count_table, meta_table$day_of_life, meta_table$studyid,
transform="none")
contrast <- cbind(c(1,1,0), c(1,-1,0))
res_ratio <- ratio_feature(res_tempted, datlist_raw, pct=0.1,
absolute=FALSE, contrast=contrast)
group <- unique(meta_table[, c("studyid", "delivery")])
plot_metafeature(res_ratio$metafeature.ratio, group)
plot_metafeature(res_ratio$metafeature.ratio, group, bws=30)
res_aggregate <- aggregate_feature(res_tempted, datlist_raw, pct=0.1,
absolute=FALSE, contrast=contrast)
res_aggregate <- aggregate_feature(res_tempted, datlist_raw, pct=0.1,
contrast=contrast)
res_aggregate <- aggregate_feature(res_tempted, mean_svd, datlist, pct=1,
#' contrast=contrast)
plot_metafeature(res_aggregate$metafeature.aggregate, group, bws=30)
)
res_aggregate <- aggregate_feature(res_tempted, mean_svd, datlist, pct=1,
contrast=contrast)
plot_metafeature(res_aggregate$metafeature.aggregate, group, bws=30)
contrast <- cbind(c(1/2,1,0), c(1/2,-1,0))
res_aggregate <- aggregate_feature(res_tempted, mean_svd, datlist, pct=1,
contrast=contrast)
plot_metafeature(res_aggregate$metafeature.aggregate, group, bws=30)
count_train <- count_table[-(1:5),]
meta_train <- meta_table[-(1:5),]
count_test <- count_table[1:5,]
meta_test <- meta_table[1:5,]
datlist_train <- format_tempted(count_train, meta_train$day_of_life, meta_train$studyid,
pseudo_count=0.5, transform="clr")
mean_svd_train <- svd_centralize(datlist_train, r=1)
res_tempted_train <- tempted(mean_svd_train$datlist, r=3, smooth=1e-5)
datlist_test <- format_tempted(count_test, meta_test$day_of_life, meta_test$studyid,
pseudo_count=0.5, transform="clr")
id_test <- meta_table$studyid=="1"
count_train <- count_table[!id_test,]
meta_train <- meta_table[!id_test,]
count_test <- count_table[id_test,]
meta_test <- meta_table[id_test,]
datlist_train <- format_tempted(count_train, meta_train$day_of_life, meta_train$studyid,
pseudo_count=0.5, transform="clr")
mean_svd_train <- svd_centralize(datlist_train, r=1)
res_tempted_train <- tempted(mean_svd_train$datlist, r=3, smooth=1e-5)
datlist_test <- format_tempted(count_test, meta_test$day_of_life, meta_test$studyid,
pseudo_count=0.5, transform="clr")
sub_test <- est_test_subject(datlist_test, res_tempted_train, mean_svd_train)
count_test <- count_test[,rownames(datlist_train[[1]])[-1]]
datlist_test <- format_tempted(count_test, meta_test$day_of_life, meta_test$studyid,
threshold=1, pseudo_count=0.5, transform="clr")
sub_test <- est_test_subject(datlist_test, res_tempted_train, mean_svd_train)
dim(datlist_test[[1]])
dim(datlist_train[[1]])
dim(count_test)
#' \code{"logit"} for logit transformation.
#' \code{"none"} for no transformation.
#' Default \code{transform="clr"} is recommended for microbiome data.
#' For data that are already transformed, use \code{transform="none"}.
#' @return A length n list of matrices as the input of \code{\link{tempted}} and \code{\link{svd_centralize}}.
#' Each matrix represents a subject,
#' with columns representing samples from this subject,
#' the first row representing the sampling time points,
#' and the following rows representing the feature values.
#' @examples See \code{\link{tempted}}.
format_tempted <- function(feature_table, time_point, subjectID,
threshold=0.95, pseudo_count=NULL, transform="clr"){
ntm <- which(table(subjectID)==1)
if(length(ntm)>0)
stop(paste('Please remove these subjects with only one time point:',
paste(names(ntm), collapse=', ')))
if (length(subjectID)!=nrow(feature_table))
stop('length of subjectID does not match feature_table!')
if (length(time_point)!=nrow(feature_table))
stop('length of time_point does not match feature_table!')
# get pseudo count
if (is.null(pseudo_count) & (transform %in% c("clr", "log_comp", "logit"))){
pseudo_count <- apply(feature_table, 1, function(x){
min(x[x!=0])/2
})
}
# keep taxon that has non-zeros in >1-threshold samples
feature_table <- feature_table[,colMeans(feature_table==0)<=threshold]
if(transform=='log_comp'){
feature_table <- feature_table+pseudo_count
feature_table <- t(log(feature_table/rowSums(feature_table)))
}else if(transform=='comp'){
feature_table <- feature_table
feature_table <- t(feature_table/rowSums(feature_table))
}else if(transform=='ast'){
feature_table <- feature_table
feature_table <- t(asin(sqrt(feature_table/rowSums(feature_table))))
}else if(transform=='clr'){
feature_table <- feature_table+pseudo_count
feature_table <- log(feature_table/rowSums(feature_table))
feature_table <- t(feature_table-rowMeans(feature_table))
}else if(transform=='logit'){
feature_table <- feature_table+pseudo_count
feature_table <- t(feature_table/rowSums(feature_table))
feature_table <- log(feature_table/(1-feature_table))
}else if(transform=='none'){
feature_table <- t(feature_table)
}else{
print('Input transformation method is wrong! log_comp is applied instead')
feature_table <- feature_table+pseudo_count
feature_table <- t(log(feature_table/rowSums(feature_table)))
}
feature_table <- rbind(time_point, feature_table)
rownames(feature_table)[1] <- 'time_point'
subID <- unique(subjectID)
nsub <- length(subID)
# construct list of data matrices, each element representing one subject
datlist <- vector("list", length = nsub)
names(datlist) <- subID
# Each slice represents an individual (unequal sized matrix).
for (i in 1:nsub){
# print(i)
datlist[[i]] <- feature_table[, subjectID==subID[i]]
datlist[[i]] <- datlist[[i]][,order(datlist[[i]][1,])]
datlist[[i]] <- datlist[[i]][,!duplicated(datlist[[i]][1,])]
}
return(datlist)
}
datlist_test <- format_tempted(count_test, meta_test$day_of_life, meta_test$studyid,
threshold=1, pseudo_count=0.5, transform="clr")
sub_test <- est_test_subject(datlist_test, res_tempted_train, mean_svd_train)
sub_test
?devtools::build()
roxygen2::roxygenise()
colnames(meta_Table)
colnames(meta_table)
apply(meta_table,2,type)
apply(meta_table,2,class)
roxygen2::roxygenise()
devtools::build_manual()
devtools::build_readme()
?devtools::build_readme()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::load_all()
?svd_centralize
?tempted_all
devtools::load_all()
?est_test_subject
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::build_manual()
roxygen2::roxygenise()
devtools::build_manual()
devtools::document()
devtools::document()
?svd_centralize
roxygen2::roxygenise()
devtools::build_manual()
roxygen2::roxygenise()
devtools::build_manual()
devtools::build_readme()
devtools::build_readme()
devtools::build_readme()
devtools::build_readme()
?devtools::build_readme()
rm(list=ls())
roxygen2::roxygenise()
?devtools::build_readme()
devtools::build_readme()
?format_tempted
load_all()
check()
devtools::build_readme()
roxygen2::roxygenise()
roxygen2::roxygenise()
devtools::build_readme()
use_readme_rmd()
devtools::use_readme_rmd()
library(devtools)
use_readme_rmd()
build_readme()
build_readme()
roxygen2::roxygenise()
roxygen2::roxygenise()
rm(list=ls())
devtools::build_readme()
ls()
devtools::build_readme()
roxygen2::roxygenise()
devtools::build_readme()
roxygen2::roxygenise()
devtools::build_readme()
devtools::build_readme()
getwd()
usethis::use_git()
usethis::use_github()
usethis::use_git()
git rm --cached path/to/file
usethis::use_git(path = "tempted")
usethis::use_git(path = "tempted/")
setwd()
getwd()
